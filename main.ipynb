{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('dados/postings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6025 entries, 0 to 6024\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   job_title       6025 non-null   object\n",
      " 1   company         6025 non-null   object\n",
      " 2   job_location    6025 non-null   object\n",
      " 3   job_link        6025 non-null   object\n",
      " 4   first_seen      6025 non-null   object\n",
      " 5   search_city     6025 non-null   object\n",
      " 6   search_country  6025 non-null   object\n",
      " 7   job level       6025 non-null   object\n",
      " 8   job_type        6025 non-null   object\n",
      " 9   job_summary     5665 non-null   object\n",
      " 10  job_skills      4960 non-null   object\n",
      "dtypes: object(11)\n",
      "memory usage: 517.9+ KB\n"
     ]
    }
   ],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como existem valores nulos, vamos tratar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['job_summary'].fillna('Missing Value', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['job_skills'].fillna('Missing Value', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6025 entries, 0 to 6024\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   job_title       6025 non-null   object\n",
      " 1   company         6025 non-null   object\n",
      " 2   job_location    6025 non-null   object\n",
      " 3   job_link        6025 non-null   object\n",
      " 4   first_seen      6025 non-null   object\n",
      " 5   search_city     6025 non-null   object\n",
      " 6   search_country  6025 non-null   object\n",
      " 7   job level       6025 non-null   object\n",
      " 8   job_type        6025 non-null   object\n",
      " 9   job_summary     6025 non-null   object\n",
      " 10  job_skills      6025 non-null   object\n",
      "dtypes: object(11)\n",
      "memory usage: 517.9+ KB\n"
     ]
    }
   ],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.drop('first_seen', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6025 entries, 0 to 6024\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   job_title       6025 non-null   object\n",
      " 1   company         6025 non-null   object\n",
      " 2   job_location    6025 non-null   object\n",
      " 3   job_link        6025 non-null   object\n",
      " 4   search_city     6025 non-null   object\n",
      " 5   search_country  6025 non-null   object\n",
      " 6   job level       6025 non-null   object\n",
      " 7   job_type        6025 non-null   object\n",
      " 8   job_summary     6025 non-null   object\n",
      " 9   job_skills      6025 non-null   object\n",
      "dtypes: object(10)\n",
      "memory usage: 470.8+ KB\n"
     ]
    }
   ],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=dataframe['job_skills'].str.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for array in words:\n",
    "    for word in array:\n",
    "        while word[0]==' ' or word[0]=='*': # algumas palavras possuiam espaço ou * no inicio e outras não, portanto padronizamos.\n",
    "            word=word[1:]\n",
    "        all_words.append(word.capitalize())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Azure',\n",
       " 'Sql',\n",
       " 'Nosql',\n",
       " 'Sql server',\n",
       " 'Oracle',\n",
       " 'Mongodb',\n",
       " 'Data pipelines',\n",
       " 'Data integration tools',\n",
       " 'Objectoriented/object function scripting languages',\n",
       " 'Python',\n",
       " 'Snowflake',\n",
       " 'Airflow',\n",
       " 'Kubernetes',\n",
       " 'Docker',\n",
       " 'Helm',\n",
       " 'Spark',\n",
       " 'Pyspark',\n",
       " 'Sql',\n",
       " 'Tdd',\n",
       " 'Pair programming',\n",
       " 'Continuous integration',\n",
       " 'Automated testing',\n",
       " 'Kafka',\n",
       " 'Storm',\n",
       " 'Sparkstreaming',\n",
       " 'Dimensional data modeling',\n",
       " 'Etl',\n",
       " 'Data management',\n",
       " 'Data classification',\n",
       " 'Python',\n",
       " 'Sql',\n",
       " 'Snowflake',\n",
       " 'Airflow',\n",
       " 'Kubernetes',\n",
       " 'Docker',\n",
       " 'Helm',\n",
       " 'Spark',\n",
       " 'Pyspark',\n",
       " 'Kafka',\n",
       " 'Storm',\n",
       " 'Etl',\n",
       " 'Tdd',\n",
       " 'Pair programming',\n",
       " 'Continuous integration',\n",
       " 'Software testing',\n",
       " 'Deployment',\n",
       " 'Streamprocessing systems',\n",
       " 'Data modeling',\n",
       " 'Schema design',\n",
       " 'Data warehouses',\n",
       " 'Dimensional data modeling',\n",
       " 'Legal compliance',\n",
       " 'Data management',\n",
       " 'Tdd',\n",
       " 'Automation',\n",
       " 'Continuous delivery',\n",
       " 'Data engineering',\n",
       " 'Data science',\n",
       " 'Business intelligence',\n",
       " 'Python',\n",
       " 'Snowflake',\n",
       " 'Airflow',\n",
       " 'Kubernetes',\n",
       " 'Docker',\n",
       " 'Helm',\n",
       " 'Spark',\n",
       " 'Pyspark',\n",
       " 'Sql',\n",
       " 'Agile engineering',\n",
       " 'Pair programming',\n",
       " 'Continuous integration',\n",
       " 'Kafka',\n",
       " 'Storm',\n",
       " 'Sparkstreaming',\n",
       " 'Data warehousing',\n",
       " 'Etl',\n",
       " 'Data classification',\n",
       " 'Data retention',\n",
       " 'Missing value',\n",
       " 'Data engineering',\n",
       " 'Ml data ops',\n",
       " 'Data mining',\n",
       " 'Data cleaning',\n",
       " 'Data normalization',\n",
       " 'Data modeling',\n",
       " 'Data enrichment',\n",
       " 'Data monitoring',\n",
       " 'Data platforms',\n",
       " 'Data frameworks',\n",
       " 'Big data technologies',\n",
       " 'Data pipelines',\n",
       " 'Machine learning',\n",
       " 'Natural language processing',\n",
       " 'Large language models',\n",
       " 'Python',\n",
       " 'Java',\n",
       " 'Bash',\n",
       " 'Sql',\n",
       " 'Git',\n",
       " 'Snowflake',\n",
       " 'Airflow',\n",
       " 'Kubernetes',\n",
       " 'Docker',\n",
       " 'Helm',\n",
       " 'Spark',\n",
       " 'Pyspark',\n",
       " 'Aws',\n",
       " 'Gcp',\n",
       " 'Azure',\n",
       " 'Nosql',\n",
       " 'Etl',\n",
       " 'Kafka',\n",
       " 'Storm',\n",
       " 'Sparkstreaming',\n",
       " 'Applied machine learning',\n",
       " 'Data management tools',\n",
       " 'Data classification',\n",
       " 'Data retention',\n",
       " 'Genderaffirming offerings',\n",
       " 'Hr',\n",
       " 'Health',\n",
       " 'Dental',\n",
       " 'Vision',\n",
       " 'Data engineer',\n",
       " 'Ml',\n",
       " 'Data ops',\n",
       " 'Data pipelines',\n",
       " 'Data pre/post processing',\n",
       " 'Data mining',\n",
       " 'Data cleaning',\n",
       " 'Data normalization',\n",
       " 'Data modeling',\n",
       " 'Data platforms',\n",
       " 'Data frameworks',\n",
       " 'Big data',\n",
       " 'Data governance',\n",
       " 'Data infrastructure',\n",
       " 'Python',\n",
       " 'Java',\n",
       " 'Bash',\n",
       " 'Sql',\n",
       " 'Git',\n",
       " 'Snowflake',\n",
       " 'Airflow',\n",
       " 'Kubernetes',\n",
       " 'Docker',\n",
       " 'Helm',\n",
       " 'Spark',\n",
       " 'Pyspark',\n",
       " 'Aws',\n",
       " 'Gcp',\n",
       " 'Azure',\n",
       " 'Nosql',\n",
       " 'Dynamodb',\n",
       " 'Etl',\n",
       " 'Kafka',\n",
       " 'Storm',\n",
       " 'Sparkstreaming',\n",
       " 'Machine learning',\n",
       " 'Data compliance',\n",
       " 'Data classification',\n",
       " 'Data retention',\n",
       " 'Data projects',\n",
       " 'Data science',\n",
       " 'Numerical methods',\n",
       " 'Simulations',\n",
       " 'Python',\n",
       " 'Pandas',\n",
       " 'Numpy',\n",
       " 'Scipy',\n",
       " 'Scikit learn',\n",
       " 'Sql',\n",
       " 'Mysql',\n",
       " 'Cloud computing',\n",
       " 'Aws',\n",
       " 'Largescale data processing',\n",
       " 'Batch processing pipelines',\n",
       " 'Hpc',\n",
       " 'Government clearance',\n",
       " 'Handson work',\n",
       " 'Team collaboration',\n",
       " 'Bonus eligibility',\n",
       " 'Full medical dental vision coverage',\n",
       " '401k matching program',\n",
       " 'Pto',\n",
       " 'Holidays',\n",
       " 'Bonus and incentive programs',\n",
       " 'Mental health program',\n",
       " 'Flexible spending accounts',\n",
       " 'Missing value',\n",
       " 'Missing value',\n",
       " 'Etl',\n",
       " 'Sql',\n",
       " 'Postgresql',\n",
       " 'Cloud',\n",
       " 'Snowflake',\n",
       " 'Aws',\n",
       " 'Python',\n",
       " 'Java',\n",
       " 'Ci/cd',\n",
       " 'Api',\n",
       " 'Sql',\n",
       " 'Databricks',\n",
       " 'Apache spark',\n",
       " 'Python',\n",
       " 'Azure functions',\n",
       " 'Azure data bricks',\n",
       " 'Ms sql',\n",
       " 'Azure service bus',\n",
       " 'Azure data factory',\n",
       " 'Azure dataflows',\n",
       " 'Devops',\n",
       " 'Delta tables',\n",
       " 'Aws',\n",
       " 'Parquet files',\n",
       " 'Healthcare',\n",
       " 'Python',\n",
       " 'Pandas',\n",
       " 'Postgresql',\n",
       " 'Bash',\n",
       " 'Aws ec2',\n",
       " 'S3',\n",
       " 'Sql',\n",
       " 'Git',\n",
       " 'Gitlab',\n",
       " 'Github',\n",
       " 'Linux',\n",
       " 'Cli',\n",
       " 'Shell programming',\n",
       " 'Ci/cd',\n",
       " 'Sql',\n",
       " 'Azure',\n",
       " 'Data factory',\n",
       " 'Dbt',\n",
       " 'Etl',\n",
       " 'Data structures',\n",
       " 'Algorithms',\n",
       " 'Async programming',\n",
       " 'Objectoriented design',\n",
       " 'Parallel programming',\n",
       " '.net',\n",
       " 'Java',\n",
       " 'Angular',\n",
       " 'Git',\n",
       " 'Cloudbased systems',\n",
       " 'Big data design',\n",
       " 'Data normalization',\n",
       " 'Queuing technologies',\n",
       " 'Metrics',\n",
       " 'Logging',\n",
       " 'Monitoring',\n",
       " 'Alerting',\n",
       " 'Restful apis',\n",
       " 'Hl7 v2.x / fhir',\n",
       " 'Ci/cd pipeline',\n",
       " 'K8s',\n",
       " 'Terraform',\n",
       " 'Electronic health records',\n",
       " 'Data analysis',\n",
       " 'Data modeling',\n",
       " 'Google cloud storage',\n",
       " 'Google bigquery',\n",
       " 'Google looker (lookml)',\n",
       " 'Power bi (dax)',\n",
       " 'Ansi sql',\n",
       " 'Relational databases',\n",
       " 'Reporting & visualization technologies',\n",
       " 'Business intelligence tools',\n",
       " 'Data visualization',\n",
       " 'Data warehousing',\n",
       " 'Data cleaning',\n",
       " 'Data validation',\n",
       " 'Project management',\n",
       " 'Office 365 (word powerpoint excel)',\n",
       " 'Business requirements gathering',\n",
       " 'Brainstorming',\n",
       " 'Problem solving',\n",
       " 'Communication',\n",
       " 'Collaboration',\n",
       " 'Teamwork',\n",
       " 'Pl/sql',\n",
       " 'Oracle 19',\n",
       " 'Airflow',\n",
       " 'Git',\n",
       " 'Python',\n",
       " 'Rest api',\n",
       " 'Accounting',\n",
       " 'Financial data',\n",
       " 'Oracle',\n",
       " 'Pl/sql',\n",
       " 'Azure',\n",
       " 'Nosql',\n",
       " '.net framework',\n",
       " 'Data integration',\n",
       " 'Data mapping',\n",
       " 'Data warehousing',\n",
       " 'Data architecture',\n",
       " 'Erd',\n",
       " 'Data recovery',\n",
       " 'C#',\n",
       " 'Apis',\n",
       " 'Windows service',\n",
       " 'Orm',\n",
       " 'Tdd',\n",
       " 'Windows scripting',\n",
       " 'Azure synapse',\n",
       " 'Adls gen 2',\n",
       " 'Azure adf',\n",
       " 'Azure nosql database',\n",
       " 'Objectoriented architecture',\n",
       " 'Serviceoriented architecture',\n",
       " 'Sql',\n",
       " 'Ansi sql',\n",
       " 'Data modeling',\n",
       " 'Data analysis',\n",
       " 'Azure cloud',\n",
       " 'Sql',\n",
       " 'Tsql',\n",
       " 'Data warehouse',\n",
       " 'Azure data lake',\n",
       " 'Azure data factory',\n",
       " 'Azure databricks',\n",
       " 'Azure synapse',\n",
       " 'Enterprise data modelling',\n",
       " 'Azure sql data warehouse (synapse)',\n",
       " 'Adf',\n",
       " 'Adls',\n",
       " 'Data migration',\n",
       " 'Data processing',\n",
       " 'Schema design',\n",
       " 'Dimensional data modelling',\n",
       " 'Data warehouse best practices',\n",
       " 'Data integration',\n",
       " 'Databricks',\n",
       " 'Ml studio',\n",
       " 'Ai/ml',\n",
       " 'Mlops',\n",
       " 'Event hub',\n",
       " 'Iot hub',\n",
       " 'Azure stream analytics',\n",
       " 'Azure analysis service',\n",
       " 'Cosmo db',\n",
       " 'Sap hana',\n",
       " 'Power bi',\n",
       " 'Devops',\n",
       " 'Ci/cd deployments',\n",
       " 'Cloud migration methodologies',\n",
       " 'Cloud migration processes',\n",
       " 'Pyspark',\n",
       " 'Azure databricks',\n",
       " 'Azure data factory',\n",
       " 'Etl',\n",
       " 'Azure cloud',\n",
       " 'Python',\n",
       " 'Data lakehouse',\n",
       " 'Agile',\n",
       " 'Devops',\n",
       " 'Azure storage',\n",
       " 'Azure cosmos db',\n",
       " 'Azure stream analytics',\n",
       " 'Structured data',\n",
       " 'Unstructured data',\n",
       " 'Missing value',\n",
       " 'Data engineering',\n",
       " 'Etl development',\n",
       " 'Data storage structures',\n",
       " 'Data processing pipelines',\n",
       " 'Data extraction',\n",
       " 'Data transformation',\n",
       " 'Data loading',\n",
       " 'Sql',\n",
       " 'Informatica etl',\n",
       " 'Informatica mdm',\n",
       " 'Informatica idq/cdq',\n",
       " 'Snowflake',\n",
       " 'Python',\n",
       " 'Spark',\n",
       " 'Batch processing',\n",
       " 'Oltp',\n",
       " 'Olap',\n",
       " 'Data warehouse architecture',\n",
       " 'Python',\n",
       " 'Sql',\n",
       " 'Postgres',\n",
       " 'Snowflake',\n",
       " 'Elasticsearch',\n",
       " 'Apache airflow',\n",
       " 'Aws',\n",
       " 'Typescript',\n",
       " 'Stream processing',\n",
       " 'Datadog',\n",
       " 'Telemetry',\n",
       " 'Gpt4',\n",
       " 'Natural language processing',\n",
       " 'Machine learning',\n",
       " 'Financial analysis',\n",
       " 'Research',\n",
       " 'Due diligence',\n",
       " 'Realtime data pipelines',\n",
       " 'Financial llm',\n",
       " 'Data engineering',\n",
       " 'Multithreading',\n",
       " 'Multiprocessing',\n",
       " 'Asynchronous programming',\n",
       " 'Concurrency primitives',\n",
       " 'Etl pipelines',\n",
       " 'Large and heterogeneous data sources',\n",
       " 'Cloud environment',\n",
       " 'Docker',\n",
       " 'Ecs',\n",
       " 'S3',\n",
       " 'Redshift',\n",
       " 'Kafka',\n",
       " 'Rds',\n",
       " 'Dbt',\n",
       " 'Azure data factory',\n",
       " 'Matillion',\n",
       " 'Fivetran',\n",
       " 'Python',\n",
       " 'Postgres',\n",
       " 'Snowflake',\n",
       " 'Apache airflow',\n",
       " 'Apache kafka',\n",
       " 'Tableau',\n",
       " 'Dbt',\n",
       " 'Fivetran',\n",
       " 'Matillion',\n",
       " 'Azure data factory',\n",
       " 'Aws glue',\n",
       " 'Aws redshift',\n",
       " 'Aws athena',\n",
       " 'Aws emr',\n",
       " 'Aws sagemaker',\n",
       " 'Spark',\n",
       " 'Hadoop',\n",
       " 'Hive',\n",
       " 'Pig',\n",
       " 'Scala',\n",
       " 'Java',\n",
       " 'Linux',\n",
       " 'Unix',\n",
       " 'Bash',\n",
       " 'Sql',\n",
       " 'Nosql',\n",
       " 'Mongodb',\n",
       " 'Cassandra',\n",
       " 'Hbase',\n",
       " 'Redis',\n",
       " 'Elasticsearch',\n",
       " 'Kibana',\n",
       " 'Logstash',\n",
       " 'Apache nifi',\n",
       " 'Apache hadoop',\n",
       " 'Apache storm',\n",
       " 'Apache spark',\n",
       " 'Apache flink',\n",
       " 'Apache airflow',\n",
       " 'Apache hive',\n",
       " 'Apache pig',\n",
       " 'Apache hbase',\n",
       " 'Apache phoenix',\n",
       " 'Apache cassandra',\n",
       " 'Apache kafka',\n",
       " 'Apache zookeeper',\n",
       " 'Apache flume',\n",
       " 'Apache sqoop',\n",
       " 'Apache parquet',\n",
       " 'Apache avro',\n",
       " 'Apache thrift',\n",
       " 'Apache arrow',\n",
       " 'Apache impala',\n",
       " 'Apache drill',\n",
       " 'Apache hcatalog',\n",
       " 'Apache hive llap',\n",
       " 'Apache phoenix',\n",
       " 'Apache spark sql',\n",
       " 'Apache flink sql',\n",
       " 'Apache beam',\n",
       " 'Apache druid',\n",
       " 'Apache kylin',\n",
       " 'Apache pinot',\n",
       " 'Apache superset',\n",
       " 'Apache zeppelin',\n",
       " 'Apache ambari',\n",
       " 'Apache ranger',\n",
       " 'Apache atlas',\n",
       " 'Apache hive metastore',\n",
       " 'Apache spark streaming',\n",
       " 'Apache flink streaming',\n",
       " 'Apache storm streaming',\n",
       " 'Apache samza',\n",
       " 'Apache apex',\n",
       " 'Apache nifi streaming',\n",
       " 'Apache kafka streams',\n",
       " 'Apache pulsar',\n",
       " 'Apache rocketmq',\n",
       " 'Apache flinkcep',\n",
       " 'Apache storm trident',\n",
       " 'Apache samza streams',\n",
       " 'Apache apex streams',\n",
       " 'Apache nifi streaming',\n",
       " 'Apache kafka streams',\n",
       " 'Apache pulsar',\n",
       " 'Apache rocketmq',\n",
       " 'Apache spark mllib',\n",
       " 'Apache flink ml',\n",
       " 'Apache mahout',\n",
       " 'Apache mxnet',\n",
       " 'Apache tensorflow',\n",
       " 'Apache pytorch',\n",
       " 'Apache keras',\n",
       " 'Apache theano',\n",
       " 'Apache cntk',\n",
       " 'Apache mxnet',\n",
       " 'Apache tvm',\n",
       " 'Apache ray',\n",
       " 'Apache spark mllib',\n",
       " 'Apache flink ml',\n",
       " 'Apache mahout',\n",
       " 'Apache mxnet',\n",
       " 'Apache tensorflow',\n",
       " 'Apache pytorch',\n",
       " 'Apache keras',\n",
       " 'Apache theano',\n",
       " 'Apache cntk',\n",
       " 'Apache mxnet',\n",
       " 'Apache tvm',\n",
       " 'Apache ray',\n",
       " 'Data analysis',\n",
       " 'Machine learning',\n",
       " 'Actuarial science',\n",
       " 'Forecasting',\n",
       " 'Predictive modeling',\n",
       " 'Healthcare',\n",
       " 'Claims data',\n",
       " 'Cpt codes',\n",
       " 'U.s. benefits',\n",
       " 'U.s. healthcare',\n",
       " 'U.s. insurance',\n",
       " 'Data architecture',\n",
       " 'Data visualization',\n",
       " 'Relational databases',\n",
       " 'Communication skills',\n",
       " 'English',\n",
       " 'Data engineering',\n",
       " 'Data pipeline design',\n",
       " 'Data pipeline construction',\n",
       " 'Data pipeline implementation',\n",
       " 'Data analytics',\n",
       " 'Data governance',\n",
       " 'Data security',\n",
       " 'Reusable data pipelines',\n",
       " 'Automation',\n",
       " 'Metadata management',\n",
       " 'Data integration',\n",
       " 'Data management',\n",
       " 'Snowflake',\n",
       " 'Data science',\n",
       " 'Machine learning',\n",
       " 'Agile development',\n",
       " 'Autosys',\n",
       " 'Cntlm',\n",
       " 'Informatica powercenter',\n",
       " 'Ibm datastage',\n",
       " 'R',\n",
       " 'Python',\n",
       " 'Java',\n",
       " 'C++',\n",
       " 'Scala',\n",
       " 'Shell scripting',\n",
       " 'Perl scripting',\n",
       " 'Sql',\n",
       " 'Pl/sql',\n",
       " 'Mongodb',\n",
       " 'Cassandra',\n",
       " 'Data pipelines',\n",
       " 'Data integration',\n",
       " 'Data preparation',\n",
       " 'Etl',\n",
       " 'Elt',\n",
       " 'Data warehousing',\n",
       " 'Data modeling',\n",
       " 'Sql',\n",
       " 'Pl/sql',\n",
       " 'Tsql',\n",
       " 'Oracle',\n",
       " 'Sql server',\n",
       " 'Python',\n",
       " 'Java',\n",
       " 'Scala',\n",
       " 'Kafka',\n",
       " 'Pubsub',\n",
       " 'Kinesis',\n",
       " 'Apache beam',\n",
       " 'Google cloud dataflow',\n",
       " 'Apache spark',\n",
       " 'Apache storm',\n",
       " 'Informatica',\n",
       " 'Azure data factory',\n",
       " 'Jira',\n",
       " 'Agile methodologies',\n",
       " 'Data engineering',\n",
       " 'Data pipelines',\n",
       " 'Cloud technologies',\n",
       " 'Etl / data orchestration',\n",
       " 'Data warehousing',\n",
       " 'Data lake solutions',\n",
       " 'Sql',\n",
       " 'Database design',\n",
       " 'Data structure',\n",
       " 'Programming languages',\n",
       " 'Devops tools',\n",
       " 'Big data',\n",
       " 'Open source',\n",
       " 'Data streaming',\n",
       " 'Architectural components',\n",
       " 'Technical leadership',\n",
       " 'Mentoring',\n",
       " 'Cloud certification',\n",
       " 'Data engineering',\n",
       " 'Cloud data engineering',\n",
       " 'Etl',\n",
       " 'Data orchestration',\n",
       " 'Sql',\n",
       " 'Nosql',\n",
       " 'Data warehouse',\n",
       " 'Data lake',\n",
       " 'Snowflake',\n",
       " 'Redshift',\n",
       " 'Databricks',\n",
       " 'Devops',\n",
       " 'Git',\n",
       " 'Jenkins',\n",
       " 'Ci/cd',\n",
       " 'Jira',\n",
       " 'Python',\n",
       " 'Java',\n",
       " 'R',\n",
       " 'C',\n",
       " 'C#',\n",
       " 'C++',\n",
       " 'Shell',\n",
       " 'Linux',\n",
       " 'Unix',\n",
       " 'Windows',\n",
       " 'Data engineering',\n",
       " 'Healthcare data',\n",
       " 'Data infrastructure',\n",
       " 'Data pipelines',\n",
       " 'Data analytics',\n",
       " 'Data modeling',\n",
       " 'Python',\n",
       " 'Pyspark',\n",
       " 'Airflow',\n",
       " 'Prefect',\n",
       " 'Palantir foundry',\n",
       " 'Databricks',\n",
       " 'Docker',\n",
       " 'Unix',\n",
       " 'Aws',\n",
       " 'Lambda',\n",
       " 'Ehr',\n",
       " 'Population health tools',\n",
       " 'Patient portals',\n",
       " 'Clinical decision support technology',\n",
       " 'Missing value',\n",
       " 'Missing value',\n",
       " 'Sql',\n",
       " 'Azure',\n",
       " 'Data factory',\n",
       " 'Dbt',\n",
       " 'Etl',\n",
       " 'Angular',\n",
       " 'Git',\n",
       " 'Data structures',\n",
       " 'Algorithms',\n",
       " 'Async programming patterns',\n",
       " 'Objectoriented design',\n",
       " 'Parallel programming',\n",
       " '.net',\n",
       " 'Java',\n",
       " 'Queuing technologies',\n",
       " 'Kafka',\n",
       " 'Sns',\n",
       " 'Rabbitmq',\n",
       " 'Metrics',\n",
       " 'Logging',\n",
       " 'Monitoring',\n",
       " 'Alerting',\n",
       " 'Restful apis',\n",
       " 'Hl7 v2.x',\n",
       " 'Fhir',\n",
       " 'System deployment',\n",
       " 'Ci/cd pipeline',\n",
       " 'K8s',\n",
       " 'Terraform',\n",
       " 'Data warehouse',\n",
       " 'Data analytics',\n",
       " 'Trino/presto',\n",
       " 'Hive metastore',\n",
       " 'Sql',\n",
       " 'Java',\n",
       " 'Scala',\n",
       " 'Go',\n",
       " 'Aws',\n",
       " 'Cloud computing',\n",
       " 'Distributed systems',\n",
       " 'Open source',\n",
       " 'Apis',\n",
       " 'Developer platforms',\n",
       " 'Ssis',\n",
       " 'Azure data factory',\n",
       " 'Sql',\n",
       " 'Tsql',\n",
       " 'C#',\n",
       " 'Powershell',\n",
       " 'Snowflake',\n",
       " 'Databricks',\n",
       " 'Apache airflow',\n",
       " 'Apache kafka',\n",
       " 'Apache spark',\n",
       " 'Aws',\n",
       " 'Aws cloud formation',\n",
       " 'Aws lake formation',\n",
       " 'Azuer',\n",
       " 'Big data',\n",
       " 'Cloud platforms',\n",
       " 'Cloud services',\n",
       " 'Compliance',\n",
       " 'Databricks',\n",
       " 'Data governance',\n",
       " 'Gcp',\n",
       " 'Infrastructure as code',\n",
       " 'Java',\n",
       " 'Kafka',\n",
       " 'Mysql',\n",
       " 'Python',\n",
       " 'Security',\n",
       " 'Snowflake',\n",
       " 'Sql',\n",
       " 'Terraform',\n",
       " 'Sql',\n",
       " 'Python',\n",
       " 'Etl',\n",
       " 'Data integration',\n",
       " 'Big data',\n",
       " 'Software development life cycle',\n",
       " 'Data analysis',\n",
       " 'Relational database',\n",
       " 'Powershell',\n",
       " 'Ms sql',\n",
       " 'Spreadsheets',\n",
       " 'Databases',\n",
       " 'Word processing',\n",
       " 'Python',\n",
       " 'Pyspark',\n",
       " 'Airflow',\n",
       " 'Aws',\n",
       " 'Emr',\n",
       " 'Etl',\n",
       " 'Sql',\n",
       " 'Computer science degree',\n",
       " 'Data engineering',\n",
       " 'Data modeling',\n",
       " 'Sql',\n",
       " 'Tsql',\n",
       " 'Pl/sql',\n",
       " 'Etl/elt',\n",
       " 'Azure data factory',\n",
       " 'Databricks',\n",
       " 'Python',\n",
       " 'C#',\n",
       " 'Javascript',\n",
       " 'Azure',\n",
       " 'Aws',\n",
       " 'Gcp',\n",
       " 'Docker',\n",
       " 'Kubernetes',\n",
       " 'Data warehousing',\n",
       " 'Data analysis',\n",
       " 'Azure synapse',\n",
       " 'Azure data factory',\n",
       " 'Etl tools',\n",
       " 'Data pipelines',\n",
       " 'Data visualization',\n",
       " 'Business intelligence',\n",
       " 'Project management',\n",
       " 'Problem solving',\n",
       " 'Analytical analysis',\n",
       " 'Training and education',\n",
       " 'Communication skills',\n",
       " 'Data development',\n",
       " 'Data application development',\n",
       " 'Data and application development policies',\n",
       " 'Data and application development standards',\n",
       " 'Data and application development procedures',\n",
       " 'Data and application development techniques',\n",
       " 'Information systems design principles',\n",
       " 'New systems design techniques',\n",
       " 'Industry standards and best practices',\n",
       " 'System and business data applications',\n",
       " 'Data engineering',\n",
       " 'Business intelligence',\n",
       " 'Data warehousing',\n",
       " 'Data infrastructure',\n",
       " 'Data pipelines',\n",
       " 'Data quality',\n",
       " 'Dashboards',\n",
       " 'Data integration',\n",
       " 'Cloud saas/paas',\n",
       " 'Microservices',\n",
       " 'Gcp cloud function',\n",
       " 'Aws lambda',\n",
       " 'Streaming data',\n",
       " 'Batch data',\n",
       " 'Bigquery',\n",
       " 'Ms sql',\n",
       " 'Data architecture',\n",
       " 'Sql',\n",
       " 'Dataflow',\n",
       " 'Pubsub',\n",
       " 'Vertex ai',\n",
       " 'Ai/ml',\n",
       " 'Snowflake',\n",
       " 'Javascript',\n",
       " 'Python',\n",
       " 'Data pipelines',\n",
       " 'Apis',\n",
       " 'Fivetran',\n",
       " 'Dbt',\n",
       " 'Data architecture',\n",
       " 'Data modeling',\n",
       " 'Technical review',\n",
       " 'Mange development velocity',\n",
       " 'Team capacity',\n",
       " 'Backlogs',\n",
       " 'Partner closely',\n",
       " 'Product team',\n",
       " 'Key assignments',\n",
       " 'Delegate assignments',\n",
       " 'Main technical point of contact',\n",
       " 'Engineering',\n",
       " 'Translate technical requirements',\n",
       " 'Hadoop',\n",
       " 'Kafka',\n",
       " 'Hive',\n",
       " 'Spark',\n",
       " 'Vertica',\n",
       " 'Sql server',\n",
       " 'Mongodb',\n",
       " 'Tsql',\n",
       " 'Python',\n",
       " 'Splunk',\n",
       " 'Big data',\n",
       " 'Relational database',\n",
       " 'Massivelyparallelprocessing',\n",
       " 'Nosql',\n",
       " 'Database infrastructure',\n",
       " 'Performance',\n",
       " 'Availability',\n",
       " 'Application requirements',\n",
       " 'Information security',\n",
       " 'Cyber security',\n",
       " 'Project management',\n",
       " 'Financials',\n",
       " 'Budget analysis',\n",
       " 'Project specifications',\n",
       " 'Testing',\n",
       " 'Project delivery',\n",
       " 'Interface',\n",
       " 'Customer contact',\n",
       " 'Technical matters',\n",
       " 'Coordination',\n",
       " 'Operational issues',\n",
       " 'Work plans',\n",
       " 'Schedules',\n",
       " 'Project estimates',\n",
       " 'Resource plans',\n",
       " 'Status reports',\n",
       " 'Communication',\n",
       " 'Organization',\n",
       " 'Presentation',\n",
       " 'Pmp',\n",
       " 'Gcp fundamentals',\n",
       " 'Bigquery',\n",
       " 'Composer',\n",
       " 'Python',\n",
       " 'Snowflake',\n",
       " 'Dlp',\n",
       " 'Pub/sub',\n",
       " 'Dataflow',\n",
       " 'Shell scripting',\n",
       " 'Sql',\n",
       " 'Security concepts',\n",
       " 'Etl migration',\n",
       " 'Sql performance tuning',\n",
       " 'Batch/streaming data processing',\n",
       " 'Kafka',\n",
       " 'Realtime data feeds',\n",
       " 'Big data architecture',\n",
       " 'Cloud architecture',\n",
       " 'Batch processing',\n",
       " 'Interactive solutions',\n",
       " 'Realtime processing',\n",
       " 'Azure',\n",
       " 'Cloud analytics',\n",
       " 'Sql',\n",
       " 'Sql dw',\n",
       " 'Sql db',\n",
       " 'Polybase',\n",
       " 'Usql',\n",
       " 'Azure adf',\n",
       " 'Event hub',\n",
       " 'Nifi',\n",
       " 'Hdinsight',\n",
       " 'Blob storage',\n",
       " 'Redis cache',\n",
       " 'Snowflake',\n",
       " 'Data lake implementations',\n",
       " 'Core modernization',\n",
       " 'Data ingestion',\n",
       " 'Hadoop certification',\n",
       " 'Spark certification',\n",
       " 'Reporting',\n",
       " 'Visualization',\n",
       " 'Unstructured data',\n",
       " 'Structured data',\n",
       " 'Scalable systems',\n",
       " 'Distributed systems',\n",
       " 'Cloud computing',\n",
       " 'Data cleansing',\n",
       " 'Data quality',\n",
       " 'Standardization',\n",
       " 'Transformation',\n",
       " 'Rationalization',\n",
       " 'Linking',\n",
       " 'Matching',\n",
       " 'Data standards',\n",
       " 'Master data',\n",
       " 'Metadata',\n",
       " 'Multiterabyte data',\n",
       " 'Data analytics',\n",
       " 'Sql',\n",
       " 'Plsql',\n",
       " 'R',\n",
       " 'Python',\n",
       " 'Data warehouse',\n",
       " 'Data integration',\n",
       " 'Data validation',\n",
       " 'Data testing',\n",
       " 'Data mapping',\n",
       " 'Data definition',\n",
       " 'Agile',\n",
       " 'Safe',\n",
       " 'Oracle',\n",
       " 'Sql',\n",
       " 'Snowflake',\n",
       " 'Healthcare',\n",
       " 'Python',\n",
       " 'Data science',\n",
       " 'Pandas',\n",
       " 'Numpy',\n",
       " 'Pyspark',\n",
       " 'Aws glue',\n",
       " 'Ec2',\n",
       " 'Lambda',\n",
       " 'Sql',\n",
       " 'Etl',\n",
       " 'Qe',\n",
       " 'Azure',\n",
       " 'Data factory pipelines',\n",
       " 'Microsoft software',\n",
       " 'Ssis',\n",
       " 'Visual studio',\n",
       " 'Server products',\n",
       " 'Office products',\n",
       " 'Sql server',\n",
       " 'Vb scripting',\n",
       " 'Data lake',\n",
       " 'Lakehouse',\n",
       " 'Data pipelines',\n",
       " 'Data engineering',\n",
       " 'Ci/cd',\n",
       " 'Cloud computing',\n",
       " 'Data warehousing',\n",
       " 'Data modeling',\n",
       " 'Data analysis',\n",
       " 'Data visualization',\n",
       " 'Agile development',\n",
       " 'Project management',\n",
       " 'Communication',\n",
       " 'Presentation',\n",
       " 'Leadership',\n",
       " 'Genrocket',\n",
       " 'Scripting',\n",
       " 'Postgresql',\n",
       " 'Sql',\n",
       " 'Api development',\n",
       " 'Synthetic data',\n",
       " 'Data masking',\n",
       " ...]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "unicas=set(all_words)\n",
    "unicas=list(unicas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python dash\n",
      "Python.org\n",
      "Python libraries\n",
      "Pyspark (python api for apache spark)\n",
      "Python/pyspark\n",
      "Pydantic\n",
      "Pysparkdataframes\n",
      "Python/r\n",
      "Pymongo\n",
      "Python testing\n",
      "Pyplot\n",
      "Pycharm\n",
      "Python 3.x\n",
      "Pylint\n",
      "Python 7+ years\n",
      "Pyramid analytics\n",
      "Pyspark/scalaspark\n",
      "Pysql\n",
      "Pyramid\n",
      "Pyvision\n",
      "Python coding\n",
      "Python programming\n",
      "Python (pyspark)\n",
      "Python development\n",
      "Python developments\n",
      "Pyarrow\n",
      "Pytorch\n",
      "Pyspark programming\n",
      "Python frameworks\n",
      "Pyodbc\n",
      "Python scripting\n",
      "Python 3\n",
      "Python developer\n",
      "Python\n",
      "Python oop\n",
      "Pytest\n",
      "Pyspark\n"
     ]
    }
   ],
   "source": [
    "procurando='Py'\n",
    "for habilidade in unicas:\n",
    "    if procurando in habilidade:\n",
    "        print(habilidade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
